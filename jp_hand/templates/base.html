<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Gesture Recognition</title>
    <style>
        body {
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #f0f0f0;
        }

        #canvas {
            border: 3px solid #000;
            box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
            width: 25%;
        }

        #video {
            position: absolute;
            top: 10px;
            right: 10px;
            width: 150px;
            height: auto;
            border: 2px solid #000;
            box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.2);
        }

        #prediction {
            position: absolute;
            bottom: 20px;
            font-size: 1.5rem;
            background: rgba(255, 255, 255, 0.8);
            padding: 10px 20px;
            border-radius: 10px;
            box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
        }
    </style>

</head>
<body>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <div id="prediction"></div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const predictionDiv = document.getElementById('prediction');

        // Access webcam
        navigator.mediaDevices.getUserMedia({ video: true })
            .then((stream) => {
                video.srcObject = stream;
            })
            .catch((err) => {
                console.error("Error accessing webcam: ", err);
            });

        // Capture and send frames to the backend every 100ms
        setInterval(() => {
            const canvasWidth = video.videoWidth;
            const canvasHeight = video.videoHeight;

            canvas.width = canvasWidth;
            canvas.height = canvasHeight;

            context.clearRect(0, 0, canvasWidth, canvasHeight);  // Clear previous frame
            context.drawImage(video, 0, 0, canvasWidth, canvasHeight);

            // Convert frame to base64
            const frame = canvas.toDataURL('image/jpeg');

            // Send the frame to the backend for processing
            fetch('/', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ image: frame })
            })
            .then(response => response.json())
            .then(data => {
                predictionDiv.innerText = `Prediction: ${data.prediction}`;
                
                // Draw the hand landmarks on the canvas
                if (data.landmarks && data.landmarks.length > 0) {
                    context.strokeStyle = "red";
                    context.lineWidth = 3;
                    for (let hand of data.landmarks) {
                        for (let landmark of hand) {
                            const x = landmark.x * canvasWidth;
                            const y = landmark.y * canvasHeight;
                            context.beginPath();
                            context.arc(x, y, 5, 0, 2 * Math.PI);
                            context.stroke();
                        }
                    }
                }
            })
            .catch((err) => {
                console.error("Error during prediction: ", err);
            });
        }, 100); // Capture and send every 100ms
    </script>
</body>
</html>
